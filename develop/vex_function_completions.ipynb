{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate VEX function completions\n",
    "\n",
    "Finally, verified signatures documentation in Houdini 16.5!\n",
    "I'll discard all previous work I did in last couple of years\n",
    "and will rely on the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "from hfs import HFS\n",
    "sys.path.append(str(HFS / 'houdini' / 'python3.10libs'))\n",
    "sys.path.append(str(HFS / 'python310' / 'lib' / 'site-packages'))\n",
    "from bookish.wiki.wikipages import parse_to_root as parse_wikipage\n",
    "from houdinihelp import vex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(node):\n",
    "    \"\"\"Evaluate possibly nested 'text' element to string.\"\"\"\n",
    "    if isinstance(node, dict):\n",
    "        return extract_text(node['text'])\n",
    "    elif isinstance(node, list):\n",
    "        return ''.join(extract_text(i) for i in node)\n",
    "    else:\n",
    "        return node\n",
    "\n",
    "\n",
    "def usages(node):\n",
    "    \"\"\"Recursively extract all 'type' values from Bookish tree.\"\"\"\n",
    "    if type(node) is dict:\n",
    "        if node['type'] == 'usage':\n",
    "            yield extract_text(node['text'])\n",
    "\n",
    "        for k in node:\n",
    "            if type(node[k]) is list:\n",
    "                for i in node[k]:\n",
    "                    for j in usages(i):\n",
    "                        yield j\n",
    "\n",
    "\n",
    "def all_usages(functions):\n",
    "    \"\"\"Convenience loop for many Bookish trees stored in a dict.\"\"\"\n",
    "    for f in functions:\n",
    "        for u in usages(functions[f]):\n",
    "            yield u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n"
     ]
    }
   ],
   "source": [
    "# Open vex.zip containing various helpcards including functions.\n",
    "# Parse Wiki files into JSON using Bookish wiki parser.\n",
    "docs = {}\n",
    "\n",
    "with zipfile.ZipFile(HFS / 'houdini' / 'help' / 'vex.zip') as z:\n",
    "    for path in z.namelist():\n",
    "        path = pathlib.PurePath(path)\n",
    "        if path.parent.stem == 'functions':\n",
    "            with z.open(path.as_posix()) as f:\n",
    "                name = path.stem\n",
    "                markup = f.read().decode()\n",
    "                docs[name] = parse_wikipage(markup)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2293\n",
      "<sig <type 'int'> <'abs'> (<arg <type 'int'> <'n'> out=False opt=None>)>\n"
     ]
    }
   ],
   "source": [
    "# Parse function usage examples from docs.\n",
    "function_usages = [vex.parse_vex(usage) for usage in all_usages(docs)]\n",
    "\n",
    "print(len(function_usages))\n",
    "print(function_usages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n",
      "point: Reads a point attribute value from a geometry\n"
     ]
    }
   ],
   "source": [
    "# Parse function summary lines from help cards.\n",
    "function_summaries = {}\n",
    "\n",
    "for func_name, page in docs.items():\n",
    "    for elem in page['body']:\n",
    "        if elem['type'] == 'summary':\n",
    "            summary_text = extract_text(elem['text'])\n",
    "            summary_text = ' '.join(summary_text.split()).rstrip('.')\n",
    "            function_summaries[func_name] = summary_text\n",
    "            break\n",
    "\n",
    "print(len(function_summaries))\n",
    "print(f\"point: {function_summaries['point']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1771 completions.\n"
     ]
    }
   ],
   "source": [
    "comps = {\n",
    "    'scope': 'source.vex -string -comment -source.hscript',\n",
    "    'completions': []\n",
    "}\n",
    "used_triggers = set()  # keep track of used completions to avoid duplicates\n",
    "\n",
    "for usage in function_usages:\n",
    "    function_name = usage.ident.name\n",
    "\n",
    "    args = []\n",
    "    for arg in usage.arglist.args:\n",
    "        if isinstance(arg, vex.VariadicArgs):\n",
    "            args.append(arg.string())\n",
    "        else:\n",
    "            args.append(arg.ident.string())\n",
    "\n",
    "    trigger = f\"{function_name}({', '.join(args)})\"\n",
    "\n",
    "    # Check if the trigger exists already.\n",
    "    if trigger in used_triggers:\n",
    "        continue\n",
    "\n",
    "    # Completion does not exist. Make a new one.\n",
    "    used_triggers.add(trigger)\n",
    "\n",
    "    completion = {'trigger': trigger}\n",
    "\n",
    "    # Build contents.\n",
    "    cargs = [f'${{{i}:{arg}}}' for i, arg in enumerate(args, 1)]\n",
    "    completion['contents'] = f\"{function_name}({', '.join(cargs)})\"\n",
    "\n",
    "    # Specify kind.\n",
    "    completion['kind'] = 'function'\n",
    "\n",
    "    # Add a summary line, if present.\n",
    "    if function_name in function_summaries:\n",
    "        completion['details'] = function_summaries[function_name]\n",
    "\n",
    "    comps['completions'].append(completion)\n",
    "\n",
    "\n",
    "print('Generated %d completions.' % len(used_triggers))\n",
    "\n",
    "\n",
    "# Write completions into a functions.sublime-completions file.\n",
    "with open('functions.sublime-completions', 'w') as f:\n",
    "    json.dump(comps, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
